# ğŸš€ Complete Deployment Guide - Cloud Monitoring Dashboard

**Author:** Zakariae El Bouzidi  
**Project:** Real-time Cloud Monitoring Dashboard with AI Integration  
**Target:** Beginner Computer Science/Engineering Students  

---

## ğŸ“‹ Table of Contents

1. [Prerequisites](#prerequisites)
2. [Quick Start (5 minutes)](#quick-start)
3. [Manual Installation](#manual-installation)
4. [Docker Deployment](#docker-deployment)
5. [Testing & Verification](#testing--verification)
6. [Troubleshooting](#troubleshooting)
7. [Project Structure](#project-structure)
8. [GitHub Deployment](#github-deployment)

---

## ğŸ”§ Prerequisites

### Required Software
- **Docker Desktop** (Recommended - Easiest method)
- **Python 3.11+** (For manual installation)
- **Git** (For cloning/pushing to GitHub)
- **Web Browser** (Chrome/Firefox/Edge)

### System Requirements
- **RAM:** 4GB minimum (8GB recommended)
- **Storage:** 2GB free space
- **OS:** Windows 10/11, macOS, or Linux
- **Network:** Internet connection for AI model download

---

## âš¡ Quick Start (5 minutes)

### Method 1: Docker (Recommended for Beginners)

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd cloud-monitoring-dashboard

# 2. Start Docker Desktop (GUI application)

# 3. Launch the entire system
docker-compose up --build -d

# 4. Wait 2-3 minutes for AI model download
# 5. Open browser: http://localhost:8000
```

**That's it! ğŸ‰ The dashboard is running!**

---

## ğŸ› ï¸ Manual Installation

### Step 1: Environment Setup

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r cloud_monitoring_dashboard/backend/requirements.txt
```

### Step 2: Install Ollama AI

```bash
# Download and install Ollama
# Visit: https://ollama.ai/download

# Pull AI model (1.3GB download)
ollama pull llama3.2:1b

# Start Ollama service
ollama serve
```

### Step 3: Launch Application

```bash
# Navigate to backend
cd cloud_monitoring_dashboard/backend

# Start the server
python main.py
```

**Access:** http://localhost:8000

---

## ğŸ³ Docker Deployment (Recommended)

### Why Docker?
- âœ… **Zero configuration** - Everything works out of the box
- âœ… **Consistent environment** - Same behavior everywhere
- âœ… **Easy cleanup** - Remove everything with one command
- âœ… **Production-ready** - Scalable and maintainable

### Docker Commands

```bash
# Start everything
docker-compose up --build -d

# View logs
docker-compose logs -f

# Stop everything
docker-compose down

# Remove everything (including data)
docker-compose down -v
```

### Docker Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚    â”‚     Ollama      â”‚
â”‚   (Port 8000)   â”‚â—„â”€â”€â–ºâ”‚   (Port 11434)  â”‚
â”‚   FastAPI +     â”‚    â”‚   Llama 3.2 1B  â”‚
â”‚   Frontend      â”‚    â”‚   AI Engine     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing & Verification

### 1. Health Check
```bash
curl http://localhost:8000/api/health
```
**Expected:** `{"status": "healthy", "ollama_status": "operational"}`

### 2. AI Test
```bash
curl http://localhost:8000/api/ai/analyze
```
**Expected:** AI analysis response with recommendations

### 3. WebSocket Test
- Open browser console on dashboard
- Check for WebSocket connection messages
- Verify real-time metrics updates

### 4. Incident Simulation
```bash
curl -X POST http://localhost:8000/api/incidents/trigger \
  -H "Content-Type: application/json" \
  -d '{"incident_id": "cpu_spike"}'
```

### 5. Complete Feature Test

| Feature | URL | Expected Result |
|---------|-----|-----------------|
| Homepage | http://localhost:8000 | System status overview |
| Dashboard | http://localhost:8000/dashboard | Interactive monitoring |
| API Docs | http://localhost:8000/docs | Complete API reference |
| Health Check | http://localhost:8000/api/health | System health status |
| Metrics | http://localhost:8000/api/metrics | Current system metrics |

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. "Docker not found"
```bash
# Solution: Install Docker Desktop
# Download from: https://docker.com/get-started
```

#### 2. "Port 8000 already in use"
```bash
# Solution: Kill existing process
# Windows:
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# macOS/Linux:
lsof -ti:8000 | xargs kill -9
```

#### 3. "Ollama AI unavailable"
```bash
# Check Ollama container
docker-compose logs ollama

# Restart Ollama
docker-compose restart ollama

# Manually pull model
docker-compose exec ollama ollama pull llama3.2:1b
```

#### 4. "WebSocket connection failed"
```bash
# Check if dashboard is running
docker-compose ps

# Restart dashboard
docker-compose restart dashboard
```

#### 5. "AI analysis taking too long"
```bash
# Check system resources
docker stats

# Increase timeout (edit docker-compose.yml)
environment:
  - OLLAMA_TIMEOUT=60
```

### Debug Commands

```bash
# View all containers
docker ps -a

# Check container logs
docker-compose logs [service-name]

# Access container shell
docker-compose exec dashboard bash
docker-compose exec ollama bash

# Monitor resource usage
docker stats

# Clean up everything
docker system prune -a
```

---

## ğŸ“ Project Structure

```
cloud-monitoring-dashboard/
â”œâ”€â”€ ğŸ³ docker-compose.yml          # Docker orchestration
â”œâ”€â”€ ğŸ³ Dockerfile                  # Container definition
â”œâ”€â”€ ğŸ“š DEPLOYMENT_GUIDE.md         # This guide
â”œâ”€â”€ ğŸ“„ README.md                   # Project overview
â”œâ”€â”€ ğŸ“„ LICENSE                     # MIT License
â”œâ”€â”€ ğŸš€ LAUNCH_PROJECT.bat          # Windows launcher
â”œâ”€â”€ ğŸš€ LAUNCH_PROJECT.sh           # Linux/macOS launcher
â”œâ”€â”€ cloud_monitoring_dashboard/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ ğŸ main.py             # FastAPI application
â”‚   â”‚   â””â”€â”€ ğŸ“¦ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ ğŸ¨ css/                # Stylesheets
â”‚       â”œâ”€â”€ âš¡ js/                 # JavaScript
â”‚       â”œâ”€â”€ ğŸ–¼ï¸ icons8-layers-16.png # Favicon
â”‚       â””â”€â”€ ğŸŒ index.html          # Dashboard UI
â””â”€â”€ templates/
    â”œâ”€â”€ ğŸ  index.html              # Homepage
    â””â”€â”€ ğŸ“– docs.html               # API documentation
```

```
## ğŸ¯ Success Criteria

Your deployment is successful when:

- âœ… **Homepage loads** at http://localhost:8000
- âœ… **Dashboard shows real-time metrics** with animated charts
- âœ… **AI analysis works** and provides intelligent insights
- âœ… **Incident simulation** triggers alerts and updates
- âœ… **WebSocket connection** shows "Connected" status
- âœ… **All API endpoints** return valid responses
- âœ… **Docker containers** are running without errors

---

## ğŸ“ˆ Next Steps

### For Learning
1. **Explore the code** - Understand FastAPI, WebSocket, AI integration
2. **Modify features** - Add new metrics, incident types, or AI prompts
3. **Extend functionality** - Add user authentication, data persistence
4. **Deploy to cloud** - AWS, Google Cloud, or Azure

### For Portfolio
1. **Document your changes** - Keep a development journal
2. **Create demo videos** - Show the dashboard in action
3. **Write blog posts** - Explain the technical challenges solved
4. **Present to peers** - Share your learning experience

---

## ğŸ¤ Support

### Getting Help
- **GitHub Issues:** Report bugs or request features
- **Documentation:** Check README.md and code comments
- **Community:** Share your implementation experience

### Contributing
- Fork the repository
- Create feature branches
- Submit pull requests
- Follow coding standards

---

**ğŸ‰ Congratulations! You've successfully deployed a professional-grade cloud monitoring system with AI integration!**

---

*Built by Zakariae El Bouzidi* 